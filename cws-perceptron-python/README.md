##基于结构化平均感知器的中文分词

实现结构化感知器

最近因为准备接手师兄的个性化分词模块，同时希望在开学之前能多学一些东西，于是开始在感知器模型上做一些实事。

一件事是在博客上写的关于感知器的[文章](http://memeda.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/2015/07/22/%E6%84%9F%E7%9F%A5%E5%99%A8%E5%AD%A6%E4%B9%A0.html)，主要包括感知器模型介绍，目标函数，更新算法。继而引出了一些感知器的变体，包括平均感知器，结构化感知器。*目前仍处于编辑状态。*

另一件事就是写出实际可用的代码。
**目标是快速开发，结构清晰。**

1. 选择Python实现

2. 不要求使用不熟悉的知识，不要求良好封装

3. 效果好

主要从[LTPCWS](https://github.com/HIT-SCIR/ltp-cws)中学习到相关处理细节：

1. 需要从训练集中提取到lexicon信息，并建立词典。

2. 中英文单词，URL，（数字）需要预处理 [暂不考虑]

3. 抽哪些特征
    
    实际抽的特征都是在输入词上抽的，与具体的标签无关。故可以认为这是emit特征（发射特征）。而转移特征可以认为是直接人为赋予的，如果是一阶马尔科夫就是前一个Label到当前label，如果是二阶，那么就是考虑前两个。

    对于emit特征，由于是针对输入字的，故与label无关。即对各label而言，emit特征可以认为是相同的；

    对于trans特征，其是在Viterbi解码时生成的。

    权值向量上，对于emit特征，每个类别都有相应的特征值，设emit特征数为N，那么需要的权值参数为N*label_num ；做一阶，则有label_num*label_num个权值参数，二阶有label_num^3个。

    一个问题是，这些权值参数该如何存储？ 是类似多元分类，为(N+label_num)*label_num的矩阵（仅对一阶有效，二阶可能需要把转移权值单独拿出来），还是把所有权值放在一起，作为一个向量？在LTPCWS中，是后者的处理方式，并使用了一个函数来映射同样的emit特征在不同label下对应的权值参数。

    为了更新方便，且易于扩展，这里也采用LTPCWS的方式组织W。

    在LTPCWS中，抽取的特征有：

    1. 当前字，左第一个字，左第二个字，右第一个字，右第二个字 

        W_c , W_l1 , W_l2 , W_r1 , W_r2

    2. 当前字类别，左第一个字类别，右第一个字类别

        类别是指，这个字是中文字符、英文字母、（标点符号）、URL等

        T_c , T_l1 , T_r1

    3. 词典信息

        以该字开始的词语的最大长度

        以改字结尾的词语的最大长度

        过该字的词语的最大长度

        单字长度均为0

        L_start , L_end , L_pass



